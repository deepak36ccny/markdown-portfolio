# -*- coding: utf-8 -*-
"""Binary_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1I7aAFyGYgqrJ0sRqsTDpEoHTVomdAJsC
"""

import pandas as pd
import numpy as np

df = pd.read_csv('train_binary.csv')
df.head()

df.shape

import cv2

train_paths = "train_images/"

def load_images(image_paths,df):
    loadedImages = []
    
    for img in df.imagesID:
        image = cv2.imread(train_paths+img)
        loadedImages.append(image)
    return loadedImages

train_images = load_images(train_paths,df)

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import matplotlib.pyplot as plt
print(train_images[100].shape)
plt.imshow(train_images[0])

def resize_images(images):
    resizedimages = []  
    for img in images:  
        img = cv2.resize(img,(256,img.shape[0]))
        resizedimages.append(img)
    return resizedimages

train_images_r = resize_images(train_images)

print(train_images_r[0].shape)
plt.imshow(train_images_r[0])

def features_to_np_array(images):
    imagenp = np.empty(shape = (len(images),images[0].shape[0],images[0].shape[1],images[0].shape[2]), dtype='uint8')
    idx = 0
    for img in images:
        imagenp[idx,:,:,:] = img[:,:,:]
        idx = idx+1
    imagenp = imagenp.reshape((imagenp.shape[0],imagenp.shape[1]*imagenp.shape[2]*imagenp.shape[3]))
    return imagenp
    
    
train_images = features_to_np_array(train_images_r)

train_images.shape

y = pd.get_dummies(df.label,columns='label')
y = np.array(y)

from sklearn.model_selection import train_test_split

X_train,X_test,y_train,y_test = train_test_split(train_images,y,test_size = 0.2,random_state=42, stratify=y)
X_train.shape

X_train_r = X_train.reshape((10054,256,256,3))
X_train_r.shape

X_test_r.shape

X_test_r = X_test.reshape((2514,256,256,3))
X_test_r.shape

import tensorflow as tf
import random as rn

# Set up your models here
# Setting the seed for numpy-generated random numbers
np.random.seed(37)

# Setting the seed for python random numbers
rn.seed(1254)

# Setting the graph-level random seed.
tf.random.set_seed(89)

from keras.models import Sequential
from keras.layers import Dense,Conv2D,Dropout,Flatten,MaxPooling2D

model = Sequential()
#model_28.add(Dense(128,input_dim = 784,activation='relu'))
model.add(Conv2D(32, kernel_size=(3, 3), input_shape= (256,256,3), border_mode='same', activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(64, 3, 3, activation='relu', border_mode='same'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(128, 3, 3, activation='relu', border_mode='same'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(256, 3, 3, activation='relu', border_mode='same'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Flatten())
model.add(Dense(2, activation='sigmoid'))
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
model.summary()

model.fit(X_train_r,y_train,epochs=15,batch_size=128, validation_data = (X_test_r, y_test))

model.save("Binary2.h5")

history = model.load_weights("Binary2.h5")

X_test_r.shape

y_train.shape

from keras.models import load_model
 
# load model
hist1 = load_model('Binary2.h5')

y_pred=model.predict(X_test_r)

import matplotlib.pyplot as plt

y_pred.shape

con_mat = tf.math.confusion_matrix(labels=y_test, predictions=y_pred).numpy()

def convert_class(y):
    
    lb_list = []
    
    for i in y:
        
        i = list(i)
        
        i_mx = max(i)
        
        i_id = i.index(i_mx)
        
        lb_list.append(i_id)
        
    return np.array(lb_list)

y_test =  convert_class(y_test)
y_pred = convert_class(y_pred)

y_test.shape

from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score

print(confusion_matrix(y_test, y_pred))

print(classification_report(y_test, y_pred, labels=[0, 1]))

print(accuracy_score(y_test, y_pred))

df2 = pd.read_excel( 'Book.xlsx')

import xlrd

df2.head

df2["Training loss"].head(15).plot(label= 'Training Loss')
df2["Validation loss"].head(15).plot(label = 'Validation Loss')
plt.title('Loss Curve', fontsize = 20)
plt.xlabel('Number of Epochs', fontsize = 16)
plt.ylabel('CrossEntropy Loss', fontsize = 16)
plt.xticks(np.arange(1,16,step = 1))
plt.legend()
plt.show()

df2["Training Accuracy"].head(15).plot(label='Training Accuracy')
df2["Validation Accuracy"].head(15).plot(label = 'Validation Accuracy')
plt.title('Accuracy Curve', fontsize=20)
plt.xlabel('Number of Epochs', fontsize = 16)
plt.ylabel('Accuracy', fontsize = 16)
plt.xticks(np.arange(1,16,step = 1))
plt.legend()
plt.show()

